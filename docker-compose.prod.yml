# ðŸš€ Docker Compose for AWS PRODUCTION
# All 3 services (PostgreSQL, Backend, Frontend) in one VM
# ðŸ›¡ï¸ DATA SAFETY: Uses named volumes for data persistence

version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: lms-postgres
    restart: always
    environment:
      POSTGRES_USER: ${DB_USER:-lms_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME:-lms_slncity}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
    volumes:
      # ðŸ›¡ï¸ CRITICAL: Named volume for data persistence
      # This volume persists even if container is removed
      # âš ï¸ NEVER use 'docker-compose down -v' in production!
      - postgres_data:/var/lib/postgresql/data

      # Initialization scripts (only run on first start when volume is empty)
      - ./server/db/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
      - ./server/db/seed-production.sql:/docker-entrypoint-initdb.d/02-seed-production.sql:ro
    networks:
      - lms-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-lms_user} -d ${DB_NAME:-lms_slncity}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # ðŸ”’ Security: Database NOT exposed to internet
    # Only accessible from backend container via internal network

  # Backend API
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile.prod
    container_name: lms-backend
    restart: always
    environment:
      NODE_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: ${DB_USER:-lms_user}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME:-lms_slncity}
      PORT: 5002
      JWT_SECRET: ${JWT_SECRET}
      FRONTEND_URL: ${FRONTEND_URL}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - lms-network
    ports:
      - "5002:5002"  # Expose backend port for direct access
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend (Nginx)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend.prod
      args:
        VITE_API_URL: ${VITE_API_URL}
    container_name: lms-frontend
    restart: always
    ports:
      - "80:80"      # HTTP
      - "443:443"    # HTTPS (if SSL configured)
    depends_on:
      - backend
    networks:
      - lms-network
    volumes:
      # SSL certificates (mount if using Let's Encrypt)
      - ./nginx/ssl:/etc/nginx/ssl:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  lms-network:
    driver: bridge

volumes:
  # ðŸ›¡ï¸ CRITICAL: Named volume for PostgreSQL data
  # This ensures data persists across container restarts and rebuilds
  #
  # âš ï¸ DATA SAFETY RULES:
  #
  # Safe commands (data preserved):
  #   âœ… docker-compose -f docker-compose.prod.yml down
  #   âœ… docker-compose -f docker-compose.prod.yml restart
  #   âœ… docker-compose -f docker-compose.prod.yml stop
  #   âœ… docker-compose -f docker-compose.prod.yml start
  #   âœ… docker-compose -f docker-compose.prod.yml up -d
  #   âœ… docker-compose -f docker-compose.prod.yml build --no-cache
  #
  # Dangerous commands (DELETES ALL DATA):
  #   âŒ docker-compose -f docker-compose.prod.yml down -v
  #   âŒ docker volume rm lms-slncity-v1_postgres_data
  #   âŒ docker volume prune
  #
  # Backup commands:
  #   docker exec lms-postgres pg_dump -U lms_user lms_slncity > backup.sql
  #   gzip backup.sql
  #
  # Restore commands:
  #   gunzip -c backup.sql.gz | docker exec -i lms-postgres psql -U lms_user -d lms_slncity
  postgres_data:
    driver: local

